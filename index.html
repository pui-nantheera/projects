<!DOCTYPE html>
<html>
    <head>
        <meta charset="UTF-8">
        <link type="text/css" rel="stylesheet" href="stylesheet.css"/>
        <link href='http://fonts.googleapis.com/css?family=Roboto+Slab:400,700' rel='stylesheet' type='text/css'>
        <link href='http://fonts.googleapis.com/css?family=Merriweather+Sans:400,700' rel='stylesheet' type='text/css'>
        <title>Pui's research</title>
        <meta name="description" content="list of researches of nantheera anantrasirichai univeristy of bristol">
        <meta charset="utf-8">
    </head>
    <body>
        <div id="header">
            <p id="name">Nantheera Anantrasirichai</p>
        </div>
        <div class="left">
            <nav class="textmenu">
                <ul>
                  <li><a href="index.html">Home</a></li>
                  <li><a href="about.html">About Pui</a></li>
                  <li><a href="research.html">Research</a></li>
                  <li><a href="publications.html">Publications</a></li>
                  <li><a href="download.html">Download</a></li>
                  <li><a href="links.html">Links</a></li>
                </ul>
            </nav>
        </div>
        <div class="body">
            <h3>Research</h3>
            <div class="researchlist">
                <h4><span class="bullet">￭</span><a href="research\volcanicUnrest.html">Automated Alert System for Volcanic Unrest</a></h4>
                    <p>Satellite radar (InSAR) can be employed to observe volcanic ground deformation, which has shown a significant statistical link to eruptions. The explosion in data has however brought major challenges associated with timely dissemination of information and distinguishing volcano deformation patterns from noise, which currently relies on manual inspection. Here, we present a novel approach to detect volcanic ground deformation automatically from InSAR images.</p>
                    <div class="line_sep"></div>
                <h4><span class="bullet">￭</span><a href="research\Palantir.html">Palantir - Real Time Inspection and Assessment of Wind Turbine Blade Health</a></h4>
                    <p>A major challenge that faces the wind turbine industry is to collect and collate the large amounts of inspection data from wind turbine blades that comes from different inspection technologies and different inspection providers. Current techniques are expensive and results are not typically known for weeks or months until after the inspection. The Palantir project will increase the capability to undertake required inspections remotely. The key innovation will be the development of a permanently installed monitoring system for wind turbine blades providing real time continuous monitoring. This system will incorporate automated analysis of the data and therefore provide near real time status of blade health.</p>
                    <div class="line_sep"></div>
                <h4><span class="bullet">￭</span><a href="research\biovisualframework.html">Bio-inspired Visual Framework for Autonomous Locomotion</a></h4>
                    <p>Vision provides us information that can be used for adaptively controlling our locomotion. However,
                      we still do not fully understand how humans perceive and use it in a dynamic environment.
                      This implies that information from visual sensors, e.g. cameras, has not yet been
                      fully employed in autonomous systems. This project will study human eye movement during
                      locomotion using a mobile eye tracker, leading to a better understanding of human perception
                      and what low-level features drive decisions.</p>
                    <div class="line_sep"></div>
                <h4><span class="bullet">￭</span><a href="research\BlineDetection.html">B-Line Quantification in Lung Ultrasound Images</a></h4>
                    <p>B-lines, defined as discrete laser-like vertical hyperechoic reverberation
                      artefacts in lung ultrasounds, have been shown to
                      correlate with extravascular lung water in adults and children on dialysis.
                      This project developed a novel automatic B-line
                      detection via an inverse problem involving the Radon transform.
                    </p>
                    <div class="line_sep"></div>
                <h4><span class="bullet">￭</span><a href="research\terrainTexture.html">Terrain Analysis for Robotics</a></h4>
                    <p>The project aims to investigate the use of artificial visual perception for the control of locomotion in legged robot. The knowledge of the way humans use vision to control locomotion is translated to the engineering disciplines of machine and robotics. The terrain type and geometry are assessed and predicted using image based sensors. The proposed methods involve texture-based image analysis using local frequency characteristics on images and videos and a novel wavelet-based descriptor to identify terrain types, classify materials and surface orientation.</p>
                    <div class="line_sep"></div>
                <h4><span class="bullet">￭</span><a href="research\CLEAR.html">Mitigating Atmospheric Distortion</a></h4>
                    <p>The project has proposed a novel method for mitigating the effects of atmospheric distortion on observed images, particularly airborne turbulence which can severely degrade a region of interest (ROI). In order to extract accurate detail about objects behind the distorting layer, a simple and efficient frame selection method is proposed, while the space-varying distortion problem is solved using region-level fusion based on the <a class="hidenlink" href="http://www-sigproc.eng.cam.ac.uk/~ngk/"  target="_blank">Dual Tree Complex Wavelet Transform (DT-CWT)</a>.</p>
                    <div class="line_sep"></div>
                <h4><span class="bullet">￭</span><a href="research\OCTimaging.html">Computer Assisted Analysis of Ocular Imaging</a></h4>
                    <p>The project developed an image enhancement method for retinal optical coherence tomography (OCT) images. The OCT is a non-invasive technique that produces cross-sectional imagery of ocular tissue. These images contain a large amount of speckle causing them to be grainy and of very low contrast. The OCT speckle originates mainly from multiple forward scattering and thus also contains some information about tissue composition, which can be useful in diagnosis. The project also analysed texture in the OCT image layers for retinal disease glaucoma. Methodology for classification and feature extraction based on robust principle component analysis of texture descriptors was established. In addition, the technique using multi-modal information fusion which incorporates data from visual field measurements with OCT and retinal photography was developed.</p>
                    <div class="line_sep"></div>
                <h4><span class="bullet">￭</span><a href="research\ruralservice.html">Rural/Distributed Services and Applications</a></h4>
                    <p>The project is part of the first theme of the <a class="hidenlink" href="http://www.iu-atc.com"  target="_blank">India-UK Advanced Technology Centre of Excellence in Next Generation Networks, Systems and Services (IU-ATC)</a>. The project has focused on the novel applications to meet the requirements in rural India.</p>
                    <div class="line_sep"></div>
                <h4><span class="bullet">￭</span><a href="research\MEDIEVaL.html">Multiview Distributed Video Coding For Wireless Multicamera Networks</a></h4>
                    <p>Distributed video coding (DVC) has recently received considerable interest as it allows shifting the complexity from the encoder to the decoder making it a attractive approach for low power systems with multiple remotely located multimedia sensor networks. The project has proposed the use of Hybrid Key/Wyner-Ziv frames (KWZ) with block-based concealment. Enhancement techniques, e.g. spatio-temporal interleaving, multi-hypothesis coding, bit-plane projection and etc., have been introduced to achieve compression efficiency. Scalabilities and surveillance have also been developed in the project.</p>
                    <div class="line_sep"></div>
                <h4><span class="bullet">￭</span><a href="research\multiview.html">Multi-view Image Compression and View Synthesis</a></h4>
                    <p>The project solved one of the key challenges for all multimedia network service providers which is efficient and effective multi-view video distribution across heterogeneous networks. Significant advances have been achieved in developing embedded image and video coding schemes based on wavelets, producing excellent rate-distortion performance and scalable functionality with unpredictable channel variations.</p>

            </div>
        </div>
        <div id="footer">
            <p>Office: room 2.34 Merchant Venturer's Building, Bristol, UK, BS8 1UB | Tel: +44 (0) 117-331-5075</p>
        </div>
    </body>
    <script>
        (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
          (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
          })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
        ga('create', 'UA-41219445-1', 'bris.ac.uk');
        ga('send', 'pageview');
    </script>
</html>
